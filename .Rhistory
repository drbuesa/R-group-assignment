#Density
plot(density(test$ACME), col = "blue", main = "Density function ACME");
# Correlations between Predictors and Response. Heatmap ---
col<- colorRampPalette(c("blue", "white", "red"))(20)
res <- cor(test[,2:99], test[,100:109]);
round(res, 2)
heatmap(x = res, col = col, symm = F)
#Check multicollinearity  ---
res <- cor(test[,100:109]);
round(res, 2)
plot(test[,100:109])
###â–Œ Last row with information 5113
which(data$Date == '20071231');
library(caret);
ggplot(test, aes(x = PC1, y = ACME)) +
geom_point(col = "blue")
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
library(leaflet);
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
m
library(devtools);
library(visdat);
test <- data[1:5113,]
select_important(y = test$HOOK, n_vars = 5, test[,100:109]);
variables <- sapply(test[,2:99], select_important, n_vars = 5, dat = test[,100:109])
table(variables)
ggplot(data.frame(prop_var[1:9]),
aes(x = 1:9 , y = prop_var[1:9])) +
geom_col(width = 0.7) +
geom_line(col = "blue") +
theme_bw() +
labs(x = "Principal Component",
y = "Percentage of Explained Variance")
barplot(prop_var)
plot(prop_var[1:10], type = "lines")
prop_var_acum <- cumsum(prop_var)
which(prop_var_acum >= 0.8)[1]
res <- cor(test[,100:109]);
round(res, 2)
plot(test[,100:109])
col<- colorRampPalette(c("blue", "white", "red"))(20)
res <- cor(test[,2:99], test[,100:109]);
round(res, 2)
heatmap(x = res, col = col, symm = F)
install.packages("leaflet");
install.packages("maps");
library(leaflet);
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
m
install.packages("maps")
install.packages("leaflet")
m
#Density
plot(density(test$ACME), col = "blue", main = "Density function ACME");
plot(density(test$HOOK), col = "blue", main = "Density function HOOK");
plot(density(test$ACME), col = "blue", main = "Density function ACME");
library(data.table);
library(ggplot2);
#Load datasets
folder_path <- "/Users/drodriguez45/Documents/GitHub/R-group-assignment/files/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
install.packages("imputeTS")
install.packages("psych")
install.packages(c("Amelia", "mice", "outliers"))
colnames(data)[1]
colnames(data)[2:99]
colnames(data)[100:456]
which(data$Date == '20071231');
var <- sapply(data[,100:456], var);
prop_var <- var / sum(var);
prop_var
ggplot(data.frame(prop_var[1:9]),
aes(x = 1:9 , y = prop_var[1:9])) +
geom_col(width = 0.7) +
geom_line(col = "blue") +
theme_bw() +
labs(x = "Principal Component",
y = "Percentage of Explained Variance")
barplot(prop_var)
plot(prop_var[1:10], type = "lines")
prop_var_acum <- cumsum(prop_var)
which(prop_var_acum >= 0.8)[1]
constant_variables <- function(x){
return(table(sapply(x,function(x){length(unique(x))>0.9*length(x)})));
}
constant_variables(data);
constant_variables <- function(x,thershold=0.9){
n_unique<- table(sapply(x,function(x){length(unique(x))>thershold*length(x)}));
accepted<-identical(as.numeric(n_unique),as.numeric(ncol(x)))
return(accepted)
}
constant_variables(solar_dataset);
constant_variables <- function(x,thershold=0.9){
n_unique<- table(sapply(x,function(x){length(unique(x))>thershold*length(x)}));
accepted<-identical(as.numeric(n_unique),as.numeric(ncol(x)))
return(accepted)
}
constant_variables(data);
constant_variables(vars);
class(vars)
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
class(vars)
var <- sapply(data[,100:456], var);
constant_variables(data[1:5113,2:99]);
constant_variables(stations);
constant_variables(vars);
folder_path <- "/Users/inies/Desktop/Master IE/R programming/2. Quizs and Project/project/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
folder_path <- "/Users/drodriguez45/Documents/GitHub/R-group-assignment/files/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
dim(data)
dim(vars)
class(vars)
constant_variables(data[1:5113,2:99]);
constant_variables2 <- function(x,threshold=0.6){
n_unique_values <- sapply(x, function(x){length(unique(x))>threshold*length(x)});
constant_variables <- names(n_unique_values)[n_unique_values == FALSE];
return(constant_variables);
}
constant_var_2 <- constant_variables2(vars);
constant_var_2;
length(constant_var_2)==ncol(vars)-1;
sum(is.na(data))
sapply(data, function(x){sum(is.na(x))});
sum(is.na(data[1:5113,2:99]))
sapply(data[1:5113,2:99], function(x){sum(is.na(x))});
sum(is.na(stations))
sum(is.na(data[1:5113,2:99]))
sapply(data[1:5113,2:99], function(x){sum(is.na(x))});
library(caret);
select_important<-function(y, n_vars, dat){
varimp <- filterVarImp(x = dat, y=y, nonpara=TRUE);
varimp <- data.table(variable=rownames(varimp),imp=varimp[, 1]);
varimp <- varimp[order(-imp)];
selected <- varimp$variable[1:n_vars];
return(selected);
}
test <- data[1:5113,]
select_important(y = test$HOOK, n_vars = 5, test[,100:109]);
variables <- sapply(test[,2:99], select_important, n_vars = 5, dat = test[,100:109])
table(variables)
folder_path <- "/Users/drodriguez45/Documents/GitHub/R-group-assignment/files/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
data
data
dim(data)
#quick view of datasets data and vars dimensions
dim(data)
dim(vars)
install.packages("data.table");
library(data.table);
install.packages("dplyr");
library(dplyr);
install.packages("ggplot2");
library(ggplot2);
install.packages("Amelia");
library(Amelia);
install.packages("mice");
library(mice);
install.packages("outliers");
library(outliers);
install.packages("caret");
library(caret);
folder_path <- "/Users/drodriguez45/Documents/GitHub/R-group-assignment/files/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
data
install.packages("ggplot2")
install.packages("dplyr")
install.packages("data.table")
install.packages("data.table")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("caret")
install.packages("caret")
install.packages("ggplot2")
folder_path <- "/Users/drodriguez45/Documents/GitHub/R-group-assignment/files/";
data <- readRDS(file.path(folder_path, "solar_dataset.RData"));
stations <- fread(file.path(folder_path, "station_info.csv"));
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
data
vars
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
constant_variables <- function(x,thershold=0.9){
n_unique<- table(sapply(x,function(x){length(unique(x))>thershold*length(x)}));
accepted<-identical(as.numeric(n_unique),as.numeric(ncol(x)))
return(accepted)
}
constant_variables(data[1:5113,2:99]);
constant_variables(stations);
constant_variables(stations);
constant_variables(stations);
constant_variables(vars);
constant_var_2 <- constant_variables2(vars[,2:101]);
var <- sapply(data[,100:456], var);
prop_var <- var / sum(var);
ggplot(data.frame(prop_var[1:9]),
aes(x = 1:9 , y = prop_var[1:9])) +
geom_col(width = 0.7) +
geom_line(col = "blue") +
theme_bw() +
labs(x = "Principal Component",
y = "Percentage of Explained Variance")
sum(prop_var[1:9])
barplot(prop_var)
plot(prop_var[1:10], type = "lines")
prop_var_acum <- cumsum(prop_var)
prop_var_acum
which(prop_var_acum >= 0.8)[1]
select_important<-function(y, n_vars, dat){
varimp <- filterVarImp(x = dat, y=y, nonpara=TRUE);
varimp <- data.table(variable=rownames(varimp),imp=varimp[, 1]);
varimp <- varimp[order(-imp)];
selected <- varimp$variable[1:n_vars];
return(selected);
}
test <- data[1:5113,]
select_important(y = test$HOOK, n_vars = 5, test[,100:109]);
variables <- sapply(test[,2:99], select_important, n_vars = 5, dat = test[,100:109])
table(variables)
library(caret);
variables <- sapply(test[,2:99], select_important, n_vars = 5, dat = test[,100:109])
table(variables)
res <- cor(test[,100:109]);
round(res, 2)
plot(test[,100:109])
col<- colorRampPalette(c("blue", "white", "red"))(20)
res <- cor(test[,2:99], test[,100:109]);
round(res, 2)
heatmap(x = res, col = col, symm = F)
ggplot(test, aes(x = PC1, y = ACME)) +
geom_point(col = "blue")
plot(density(test$ACME), col = "blue", main = "Density function ACME");
install.packages("leaflet");
library(leaflet);
install.packages("maps");
library(maps)
install.packages("maps")
install.packages("leaflet")
mapStates = map("state", fill = TRUE, plot = FALSE)
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
mapStates = map("state", fill = TRUE, plot = FALSE)
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
missmap(vars)
constant_variables(vars[,2:101]);
vars_cleansed_amelia<- (completed_data$imputations$imp1 + completed_data$imputations$imp2+ completed_data$imputations$imp3)/3;
completed_data
install.packages("skimr")
library(skimr)
skim(vars)
completed_data$imputations$imp1
constant_variables(vars);
constant_variables(data[1:5113,2:99]);
constant_variables(stations);
install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")
chart.Correlation(test[,100:109], histogram=TRUE, pch=19)
mtcars
install.packages("outliers");
install.packages("outliers")
library(data.table);
#packages load up
install.packages("data.table");
install.packages("data.table")
#TEAM used skimr library to get a high overview in the data for var.
#see blog: https://www.littlemissdata.com/blog/simple-eda
skim(vars)
install.packages("skimr")
install.packages("skimr")
library(skimr)
#TEAM used skimr library to get a high overview in the data for var.
#see blog: https://www.littlemissdata.com/blog/simple-eda
skim(vars)
summary(vars)
#Load datasets
folder_path <- "../project/files/";
vars <- readRDS(file.path(folder_path, "additional_variables.RData"));
summary(vars)
#TEAM used skimr library to get a high overview in the data for var.
#see blog: https://www.littlemissdata.com/blog/simple-eda
skim(vars)
outlier(vars_no_null) #Q-Q plot of mahalanobis values versus the quantiles of the 100 columns from psych package
#Analysis for solar_data set PCAs to see where the Percentage of Explained Variance is more relevant.
var <- sapply(data[,100:456], var);
ggplot(data.frame(prop_var[1:9]),
aes(x = 1:9 , y = prop_var[1:9])) +
geom_col(width = 0.7) +
geom_line(col = "blue") +
theme_bw() +
labs(x = "Principal Component",
y = "Percentage of Explained Variance")
barplot(prop_var)
plot(prop_var[1:10], type = "lines")
#GGPLOT ---
library(ggplot2)
ggplot(test, aes(x = PC1, y = ACME)) +
geom_point(col = "blue")
#Density
plot(density(test$ACME), col = "blue", main = "Density function ACME");
#Maps
mapStates = map("state", fill = TRUE, plot = FALSE)
m <- leaflet(data = mapStates) %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) %>%
addCircles(data = stations, lng = ~elon, lat = ~nlat, popup = ~stid, color = 'red');
m
constant_variables <- function(x,threshold=0.9){
n_unique<- table(sapply(x,function(x){length(unique(x))>threshold*length(x)}));
accepted<-identical(as.numeric(n_unique),as.numeric(ncol(x)))
return(accepted)
}
constant_variables(data[1:5113,2:99]);
constant_variables(stations);
constant_variables(vars);
constant_variables(stations);
stations <- fread(file.path(folder_path, "station_info.csv"));
constant_variables(stations);
#Validation technique to find the specific column names for dataset vars (additional_variables)
#where there are less than 60% unique values
constant_variables2 <- function(x,threshold=0.6){
n_unique_values <- sapply(x, function(x){length(unique(x))>threshold*length(x)});
constant_variables <- names(n_unique_values)[n_unique_values == FALSE];
return(constant_variables);
}
constant_var_2 <- constant_variables2(vars[,2:101]);
constant_var_2;
length(constant_var_2)==ncol(vars[,2:101]);
#Validation technique to find missing values in the data sets. NAs
#It is recognized that no NAs exist both for data (solar_dataset) and stations (stations_info)
# Up to 7% NAs exist for vars (additional_variables dataset)
sum(is.na(data[1:5113,2:99]))
sapply(data[1:5113,2:99], function(x){sum(is.na(x))});
sum(is.na(stations))
sapply(stations, function(x){sum(is.na(x))});
sum(is.na(vars[,2:101]));
sapply(vars[,2:101], function(x){sum(is.na(x))});
sapply(vars[,2:101], function(x){100*(sum(is.na(x)))/length(x)});
as.numeric(sort(sapply(vars[,2:101], function(x){100*(sum(is.na(x)))/length(x)}),decreasing = TRUE)[1]);
# After giving a quick overview check on vars (additional_variables dataset) it is recognized that a large
# amount of values as zero exist. There are columns with up to 76% values as zero (column V4233)
sort(sapply(vars[,2:101], function(x){100*(sum(x==0,na.rm = TRUE))/length(x)}),decreasing = TRUE)[1];
as.numeric(sort(sapply(vars[,2:101], function(x){100*(sum(is.na(x))+sum(x==0,na.rm = TRUE))/length(x)}),decreasing = TRUE))[1];
as.numeric(sort(apply(vars[,2:101],MARGIN=1, function(x){100*(sum(x==0,na.rm = TRUE)+sum(is.na(x)))/length(x)}),decreasing = TRUE))[1];
#TEAM used skimr library to get a high overview in the data for var.
#see blog: https://www.littlemissdata.com/blog/simple-eda
skim(vars)
#lets aim to fill up the missing values using Amelia package.
missmap(vars)
# calling to amelia function; m=3, this parameter is the number of data set results generated through Amelia.
#after Amelia is used we get 0% missing values.
View(vars)
completed_data <- amelia(vars, m=3, idvars = c("Date"));
save.image("/cloud/project/.RData")
boxplot(vars_no_null_clean) #versus the boxplot of the clean dataset without outliers
vars_no_null_scaled <- as.data.frame(scale(vars_no_null)) #Scaling the data with outliers.
vars_no_null_clean_scaled <- as.data.frame(scale(vars_no_null_clean)) #Scaling the data without outliers. Option if we remove outliers.
boxplot(data2)
data2 <- data[1:5113,2:99] #excluding the date in the solar_dataset in which EDA will be performed
t(sapply(data2, summary))
boxplot(data2)
boxplot(vars_no_null_clean) #versus the boxplot of the clean dataset without outliers
vars_no_null_scaled <- as.data.frame(scale(vars_no_null)) #Scaling the data with outliers.
library(imputeTS)
vars2<-vars[1:6909,2:101] #excluding the date in the dataset in which EDA will be performed
vars_no_null<-na_mean(vars2,option='median') #filling-in NAs with median (didn't use mean so that data won't be affected by outliers)
data2 <- data[1:5113,2:99] #excluding the date in the solar_dataset in which EDA will be performed
t(sapply(data2, summary)) #performing EDA to the solar_dataset
boxplot(data2) #boxplot
boxplot(data2) #boxplot
boxplot(data2$ACME) #boxplot
boxplot(data2$ACME) #boxplot
